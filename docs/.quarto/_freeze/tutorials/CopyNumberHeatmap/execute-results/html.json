{
  "hash": "f48c97c6d8f0cf2b8ee7c941bfbbbe96",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tutorial: Copy Number Heatmaps\"\nwarning: false\nmessage: false\nfig.width: 7\nfig.height: 5\nfig.align: \"center\"\n---\n\n\n\n\nThere is a wealth of copy number data bundled within `GAMBLR.data` in the form of\nsegmented copy number profiles. \nThis tutorial will give you an overview of this data. It will also demonstrate\nhow to process segmented data into a set of bins\nsuch that the data can be represented as a matrix of CN values or log ratios. \n\n## Prepare setup\n\nWe will first import the necessary packages:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(GAMBLR.open)\nsuppressMessages(library(dplyr))\n```\n:::\n\n\n\n\n## Metadata\n\nAs usual, we typically begin an analysis by loading the metadata and restricting\nthe rows to samples of interest based on any number of criteria. Here, we'll \nseparately look at the data from WGS (`genome` seq_type) and whole exome sequencing\n`capture` seq_type. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndlbcl_genome_meta = suppressMessages(get_gambl_metadata(seq_type_filter = \"genome\")) %>%\n                    filter(pathology==\"DLBCL\")\n\ndlbcl_exome_meta = suppressMessages(get_gambl_metadata(seq_type_filter = \"capture\")) %>%\n                    filter(pathology==\"DLBCL\")\n\n#remove any duplicate sample_id/seq_type combinations\ng_meta_clean = check_and_clean_metadata(dlbcl_genome_meta,\n                                      duplicate_action = \"keep_first\")\n#remove any duplicate sample_id/seq_type combinations\ne_meta_clean = check_and_clean_metadata(dlbcl_exome_meta,\n                                      duplicate_action = \"keep_first\")\n\nnrow(g_meta_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 529\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(e_meta_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1783\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThis shows that we have data from 529 genomes and 1783 exomes just from DLBCLs. \n\n## Projections\n\nThe number of samples that have copy number results available isn't necessarily going to match this. Importantly, some studies\nare older and relied on the `grch37` (i.e. hg19) genome build whereas other studies used some flavour of `hg38`. In GAMBL,\nwe aim to *project* all results to both `grch37` and `hg38` so results are relatively comparable between studies. However,\nfor efficiency, GAMBLR.data doesn't have both projections for every data set (sorry!). Let's start by determining\nwhich of our samples in the metadata have data available for in case there are some results only available for one or the other\n*projection*.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng_segments_grch37 = get_cn_segments(these = g_meta_clean,\n                                    projection = 'grch37')\n\ng_segments_hg38 = get_cn_segments(these = g_meta_clean,\n                                    projection = 'hg38')\n\nlength(unique(g_segments_grch37$ID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 214\n```\n\n\n:::\n\n```{.r .cell-code}\nlength(unique(g_segments_hg38$ID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 48\n```\n\n\n:::\n:::\n\n\n\n\nWe seem to only have copy number segments available from 48 samples for hg38. \nFor grch37 we have data from 214 samples. How about the exome data?\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ne_segments_grch37 = get_cn_segments(these = e_meta_clean,\n                                    projection = 'grch37')\n\ne_segments_hg38 = get_cn_segments(these = e_meta_clean,\n                                    projection = 'hg38')\n\nlength(unique(e_segments_grch37$ID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\nlength(unique(e_segments_hg38$ID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\nOuch! We only provided copy number data from `genome` samples (so far). Let's proceed with the largest data set, \nwhich is the `genome` samples and grch37 projection.\n\n## From segments to bins\n\nSegmented copy number data can be difficult to work with for a variety of reasons. For any coordinate in the genome, it's unnecessarily\ncomplicated to determine the copy number of all samples. We simplify this by breaking the genome into a series of *bins* and determining\nthe copy number state of each bin across all samples. This yields a N by M matrix where N is the number of samples with copy number data\nand M is the number of bins. The `segmented_data_to_cn_matrix` function in `GAMBLR.utils` makes this easy. \nIn this example, we'll do this to our 214 using 2500 bins. I've provided the metadata here\neven though it's not strictly necessary. This can be useful if you pass seg_data that contains rows from patients that you don't\nplan to analyze. Those rows will be removed before the slow process begins. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime_start = Sys.time();\ndlbcl_cn_binned = segmented_data_to_cn_matrix(\n                                  seg_data = g_segments_grch37,\n                                  strategy=\"auto_split\",\n                                  n_bins_split=2500,\n                                  these_samples_metadata = g_meta_clean)\ntime_end = Sys.time();\nelapsed = round(time_end - time_start)\nprint(elapsed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 19 secs\n```\n\n\n:::\n:::\n\n\n\n\nThat took 19 to finish. As you might imagine, increasing the n_bins_split value will make this process\nslower but will increase the resolution of your analysis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevery_seg = get_cn_segments(get_gambl_metadata())\nlength(unique(every_seg$ID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 448\n```\n\n\n:::\n\n```{.r .cell-code}\ntime_start = Sys.time();\nall_cn_binned = segmented_data_to_cn_matrix(\n                                  seg_data = every_seg,\n                                  strategy=\"auto_split\",\n                                  n_bins_split=2500) #no metadata provided\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"missing these_samples_metadata\"\n```\n\n\n:::\n\n```{.r .cell-code}\ntime_end = Sys.time();\nelapsed = round(time_end - time_start)\nprint(elapsed)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 28 secs\n```\n\n\n:::\n:::\n\n\n\n\nAs you can see, the process took considerably longer this time because of the additional samples that weren't dropped. \n\n\nAs you might have guessed from the `strategy` parameter, there are other strategies for converting segmented data into a\ncopy number matrix that don't rely on equal-sized bins. The other options are 'custom_regions','cytobands' and 'GISTIC'. \nEach of these will be covered in another tutorial. You can find out more about these in the `segmented_data_to_cn_matrix` documentation.  \n\n## DLBCL Copy Number Heatmap\n\nLet's start with the most basic example. Using the copy number matrix we just created, we run `pretty_CN_heatmap`. As for\nmost other functions, you have to provide your metadata table via *these_samples_metadata*. You can often unambiguously refer\nto this parameter with the word *these*. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate a basic genome-wide CN heatmap\npretty_CN_heatmap(cn_state_matrix=dlbcl_cn_binned,\n                  these_samples_metadata = g_meta_clean,\n                  hide_annotations = \"chromosome\")\n```\n\n::: {.cell-output-display}\n![](CopyNumberHeatmap_files/figure-html/dlbcl_heatmap-1.png){width=672}\n:::\n:::\n\n\n\n\n## Copy Number Heatmap for everything\n\nIn an earlier example, we generated a larger matrix from all the `grch37` copy number data in `GAMBLR.data`. There are\n`nrow(all_cn_binned)` samples in there. Let's see what that looks like in a heatmap. This time, we'll tell the function\nto scale the copy number values to the average ploidy of each sample using `scale_by_sample`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_genome_meta = get_gambl_metadata()\nall_genome_meta = check_and_clean_metadata(all_genome_meta,\n                                      duplicate_action = \"keep_first\")\n#drop any genomes that don't have copy number data\n\nall_genome_meta = dplyr::filter(all_genome_meta,sample_id %in% rownames(all_cn_binned))\n# Generate a genome-wide CN heatmap without clustering\n# Instead, we'll order samples based on pathology and lymphgen\npretty_CN_heatmap(cn_state_matrix=all_cn_binned,\n                  these_samples_metadata = all_genome_meta,\n                  scale_by_sample = TRUE,\n                  cluster_rows=F,\n                  metadataColumns = c(\"pathology\",\"lymphgen\"),\n                  sortByMetadataColumns = c(\"pathology\",\"lymphgen\"),\n                  bin_label_nudge = 1.08,\n                  labelTheseGenes = c(\"CDKN2A\",\"TP53\"),\n                  hide_annotations = \"chromosome\")\n```\n\n::: {.cell-output-display}\n![](CopyNumberHeatmap_files/figure-html/all_heatmap-1.png){width=672}\n:::\n:::",
    "supporting": [
      "CopyNumberHeatmap_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}